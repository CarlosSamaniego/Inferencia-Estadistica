{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastes no paramétricos.\n",
    "\n",
    "En el capítulo anterior hemos visto toda una batería de contrastes de hipótesis basados en parámetros poblaciones como la media, la proporción de éxitos y la desviación típica.\n",
    "\n",
    "En este tipo de contrastes, suponemos que conocemos el tipo de distribución de la población. Lo que no conocemos es uno o más parámetros de los que depende la distribución. Estos son conocidos contrastes paramétricos.\n",
    "\n",
    "Ahora, responder preguntas del tipo ¿en qué nos basamos para decir que una población sigue una normal? Este tipo de preguntas son las que intentan responder los **contrastes no paramétricos**. Son contrastes donde la hipótesis nula será suponer que la población sigue una cierta distribución.\n",
    "\n",
    "Una de las técnicas más conocidas para estudiar los cotrastes no paramétricos son los test de bondad y ajuste o tests $\\chi^2$.\n",
    "\n",
    "El contraste que intentamos estudiar es del siguiente tipo:\n",
    "$$\\left\\{\\begin{array}{cl}H_0:&\\mbox{la distribución de $X$ es del tipo $X_0$}\\\\H_1:&\\mbox{la distribución de $X$ no es del tipo $X_0$}\\end{array}\\right.$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas Gráficas.\n",
    "\n",
    "Supongamos que nuestra variable aleatoria $X_0$ es continua. Para comprobar si una determinada muestra proviene de $X_0$, lo primero que podemos hacer es realizar pruebas gráficas como histogramas.\n",
    "\n",
    "A partir de dichos histogramas podemos \"estimar\" la función de densidad de la muestra y ver si dicha función de densidad se parece o no a la de $X_0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "\n",
    "Consideremos iris. Concretamente la anchura de los sépalos (Sepal.Width). Queremos ver a qué se puede aproximar dicha variable. Vamos realizar un gráfico de la estimación de la función de densidad de la muestra usando la función density de R:\n",
    "\n",
    "``muestra <- iris$Sepal.Width``\n",
    "\n",
    "``plot(density(muestra),main = \"Estimación de la densidad\")``\n",
    "\n",
    "Graficamos ahora una normal con los parámetros $\\mu$ y $\\sigma$ elegidos \"naturalmente\":\n",
    "\n",
    "``muestra <- iris$Sepal.Width``\n",
    "\n",
    "``plot(density(muestra),main = \"Estimación de la densidad\")``\n",
    "\n",
    "``x <- seq(from=1, to=5, by=0.01)``\n",
    "\n",
    "``mu <- mean(muestra)``\n",
    "\n",
    "``sigma <- sd(muestra)``\n",
    "\n",
    "``lines(x,dnorm(x,mean=mu,sd=sigma),col=\"red\")``\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro tipo de prueba gráfica que podemos realizar son los llamados **gráficos cuantil-cuantil** o **Q-Q-plots**.\n",
    "\n",
    "Este tipo de gráficos compara los **cuantiles observados de la muestra** con los **cuantiles teóricos de la distribución hipotética**.\n",
    "\n",
    "La función de R que realiza un gráfico de este tipo es la función **qqPlot** del paquete **car**:\n",
    "\n",
    "``qqPlot(x,distribution,...)``\n",
    "\n",
    "donde \n",
    "\n",
    "``x`` es el vector con la muestra.\n",
    "\n",
    "``distribution`` es el nombre de la distribución hipotética: ``norm``, ``binom``, ``poisson``, etc (ver [aquí](https://www.rdocumentation.org/packages/EnvStats/versions/2.3.1/topics/Distribution.df) los distintos tipos de distribución posible junto con su correspondiente abreviatura)\n",
    "\n",
    "``...`` parámetros de la distribución igualando su nombre habitual (mean para la media, sd para la desviación, df para grados de libertad, etc).\n",
    "\n",
    "qqPlot añade por defecto una línea que une los Q-Q puntos correspondientes al primer y tercer cuantil: se llama recta cuartil-cuartil. Un buen ajuste de los Q-Q puntos a esta recta significa que la muestra se ajusta a la distribución teórica, pero posiblemente con parámetros diferentes a los especificados. \n",
    "\n",
    "También añade dos curvas discontinuas que abrazan una región de confianza del 95%. Esta región contendría todos los Q-Q puntos en un 95% de las ocasiones que tomáramos una muestra de la distribución teórica del mismo tamaño que la nuestra. Por lo tanto si todos los Q-Q puntos caen dentro de esta franja, no hay evidencia para rechazar que la muestra provenga de la distribución teórica.\n",
    "\n",
    "Se pueden usar los parámetros usuales de plot para poner nombres a los ejes, títulos, modificar el estilo de puntos, etc, y otros parámetros específicos para modificar el aspecto del gráfico. Por ejemplo col.lines sirve para especificar el color de las líneas que añade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "\n",
    "``qqPlot(x = muestra, distribution = \"norm\", mean = mu, sd = sigma)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test $\\chi^2$ de Pearson\n",
    "\n",
    "Suponemos que disponemos de los valores de una muestra de tamañao $n$ de la variable $X$ que nos da los valores $x_1,x_2,\\cdots,x_n$.\n",
    "\n",
    "A continuación clasificamos los valores $x_i$, $i=1,...,n$, en $k$ clases. La elección de estas clases depende del problema estudiado y del contexto del mismo.\n",
    "\n",
    "Sean $n_1,n_2,...,n_k$ el número de valores en la muestra que están en cada clase. Obtenemos lo que se conoce como **tabla de frecuencias empíricas**:\n",
    "\n",
    "|Clases|1   |2   |... |k   |Total|\n",
    "|:--:  |:--:|:--:|:--:|:--:|:--: |\n",
    "|Frecuencias empíricas|$n_1$|$n_2$|...|$n_k$|n|\n",
    "\n",
    "El siguiente paso es obtener la tabla de la función de probabilidad de la variable discreta $X_k$ de valores $\\{1,2,3,...,k\\}$ con función de probabilidad $P(X_k=i)=P(X_0\\in\\mbox{Clase }i),$ para $i=1,\\cdots,k$.\n",
    "\n",
    "Esta función de probabilidad tiene que hallarse a partir del conocimiento de $X_0$. Si desconocemos algunos de los parámetros de los que depende $X_0$, los tendremos que estimar usando estimadores de máxima verosimilitud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pearson_chi.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El test $\\chi^2$ o **test de bondad de ajuste** se basa en que, si la hipótesis nula es cierta, las frecuencias empíricas y las teóricas son parecidas. Luego, por el Teorema del Límite Central, el estadístico siguiente: \n",
    "\n",
    "$$\\chi^2=\\sum_{i=1}^k\\frac{(\\mbox{frec.empíricas }i-\\mbox{ frec.teóricas }i)^2}{\\mbox{frec.teórica }i}=\\sum_{i=1}^k\\frac{(n_i-e_i)^2}{e_i}$$ \n",
    "\n",
    "es casi una $\\chi^2_{k-1}$. Si $\\chi^2_0$ es el valor del estadístico de contraste anterior en nuestra muestra, entonces el p-valor vale $P(\\chi^2_{k-1}\\ge\\chi_0^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condiciones de la prueba $\\chi^2$ de Pearson\n",
    "\n",
    "Como este test está basado en el Teorema del Límite Central, se tienen que verificar las siguientes condiciones:\n",
    "\n",
    "* El tamaño de la muestra debe ser grande ($\\ge 30$)\n",
    "\n",
    "* Las clases deben cubrir todos los resultados posibles y ninguna puede quedar vacía ($n_i>0$ para toda $i$ y $\\sum n_i=n$).\n",
    "\n",
    "* Las frecuencias teóricas deben, cada una, ser $\\ge 5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "\n",
    "Imaginemos que queremos ver si un dado está trucado o no (es decir, si $X_0$ es la variable aleatoria dada por el número de salida del dado, entonces $X_0\\sim U\\{1,2,3,4,5,6\\}$).\n",
    "\n",
    "Si no está trucado, cada resultado tiene probabilidad $P(X_0=i)=1/6$. Esta sería la función de distribución de la variable $X_k$.\n",
    "\n",
    "Las clases serían los posibles valores que puede tener el dado al lanzarse. La distribución teórica queda entonces como \n",
    "\n",
    "|$X_k$|1|2|3|4|5|6|Total|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|$P(X_k=i)$|1/6|1/6|1/6|1/6|1/6|1/6|1|\n",
    "\n",
    "Nos dicen que el dado se lanza 120 veces y se han obtenido los siguientes resultados:\n",
    "\n",
    "|Clase|1|2|3|4|5|6|Total|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|Frec.Empir|20|22|17|18|19|24|120|\n",
    "\n",
    "¿Tenemos evidencia de que el dado esté trucado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla de frecuencias teóricas viene dada por \n",
    "\n",
    "|Clase     |1         |2         |3         |4         |5         |6         |Total|\n",
    "|:--:      |:--:      |:--:      |:--:      |:--:      |:--:      |:--:      |:--: |\n",
    "|Frec.Teor.| 120/6=20 | 120/6=20 | 120/6=20 | 120/6=20 | 120/6=20 | 120/6=20 | 120 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empiricas <- c(20,\t22,\t17,\t18,\t19,\t24)\n",
    "\n",
    "chi2 <- sum((empiricas - 20)^2 /20)\n",
    "\n",
    "p_valor <- pchisq(chi2,5,lower.tail = FALSE)\n",
    "\n",
    "p_valor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolución con R\n",
    "\n",
    "Usamos la función \n",
    "\n",
    "chisq.test(x, p=...,rescale.p=...,simulate.p.value=...)\n",
    "\n",
    "donde\n",
    "\n",
    "* x es el vector o la tabla de frecuencias absolutas observadas de las clases en la muetra (es decir, $x=c(n_1,n_2,...,n_k)$)\n",
    "\n",
    "\n",
    "* p es el vector de las probabilidades teóricas de las clases para la distribución que queremos contrastar. O sea que $p=c(p_1,p_2,...,p_k)$ donde $p_k=P(X_0\\in\\mbox{Clase }i)$\n",
    "\n",
    "\n",
    "* rescale.p es un parámetro lógico que, si se iguala a TRUE, indica que los valores de p no son probabilidades, sino proporcionales a las probabilidades; esto hace que R tome como probabilidades teóricas los valores de p partidos por su suma para que sumen 1. Por defecto está en FALSE.\n",
    "\n",
    "\n",
    "* simulate.p.value es un parámetro lógico que indica a la función si debe optar por una simulación para el cálculo del p-valor. Por defecto está en FALSE. Si alguna de las condiciones para el uso de la prueba $\\chi^2$ de Pearson tendremos que especifarlo como TRUE y R realizará una serie de replicaciones aleatorias de la situación teórica. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.** \n",
    "\n",
    "Consideremos iris. Imaginemos que queremos ver si en una muestra de tamaño 10 hay la misma cantidad de flores de las tres especies (set.seed(2020))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set.seed(2020)\n",
    "\n",
    "muestra.flores <- sample(iris$Species,10,replace=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|X_k|1|2|3|Total|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|P(X_k=i)|1/3|1/3|1/3|1|\n",
    "\n",
    "|Clase|1|2|3|Total|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|freq.teor|10/3|10/3|10/3|10|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo Importante.**\n",
    "\n",
    "Un técnico de medio ambiente quiere estudiar el aumento de temperatura del agua a dos kilómetros de los vertidos de agua autorizados de una planta industrial.\n",
    "\n",
    "El responsable de la empresa afirma que estos aumentos de temperatura siguen una ley $N(3.5,0.7)$ (décimas de grado). El técnico lo posa en entredicho. Para decidirlo toma una muestra aleatoria de 40 observaciones del aumento de las temperaturas (en décimas de grado) y se obtienen los resultados siguientes:\n",
    "\n",
    "|Rango de temperaturas|Frecuencias|\n",
    "|:--:|:--:|\n",
    "|1.45-1.95|2|\n",
    "|1.95-2.45|1|\n",
    "|2.45-2.95|4|\n",
    "|2.95-3.45|15|\n",
    "|3.45-3.95|10|\n",
    "|3.95-4.45|5|\n",
    "|4.45-4.95|3|\n",
    "\n",
    "¿Hay evidencia de que la sospecha del técnico sea verdadera?\n",
    "\n",
    "|Rango de temperaturas|(-inf,1.95]|(1.95,2.45]|(2.45,2.95]|(2.95,3.45]|(3.45,3.95]|(3.95,4.45]|(4.45,+inf)|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|Frecuencias| 2|1|4|15|10|5|3|\n",
    "\n",
    "**1.** Calcular las frecuencias teóricas.\n",
    "\n",
    "**2.** Observar si se cumplen directamente las condiciones del test $\\chi^2$ de Pearson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extremos_izq <- c(-Inf,1.95,2.45,2.95,3.45,3.95,4.45)\n",
    "\n",
    "extremos_der <- c(1.95,2.45,2.95,3.45,3.95,4.45,Inf)\n",
    "\n",
    "empiricas <- c(2,1,4,15,10,5,3)\n",
    "\n",
    "n <- sum(empiricas)\n",
    "\n",
    "prob_teor <- pnorm(extremos_der, mean = 3.5, sd = 0.7) - pnorm(extremos_izq, mean = 3.5, sd = 0.7)\n",
    "\n",
    "freq_teor <- n * prob_teor\n",
    "\n",
    "freq_teor\n",
    "\n",
    "chisq.test(empiricas,p = prob_teor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test $\\chi^2$ de Pearson con parámetros desconocidos.\n",
    "\n",
    "El ejemplo anterior no es realista en el sentido que la mayoría de las veces desconoceremos la media y la desviación típica.\n",
    "\n",
    "Cuando la variable $X_0$ (no necesariamente normal) de la población de contraste dependa de algunos parámetros, necesitamos su valor para calcular las frecuencias teóricas.\n",
    "\n",
    "La manera de resolver este inconveniente es estimar dichos parámetros usando el estimador de máxima verosimilitud correspondiente. Una vez estimados los parámetros de los que depende $X_0$, podemos usar el test de bondad de ajuste pero ahora los grados de libertad de la $\\chi^2$ son $k-1-\\#$parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "\n",
    "Se quiere determinar si el número de veces que aparece la secuencia GATACA en una cadena de ADN de longitud 1000 sigue una ley Poisson. Se toman varias muestras de cadenas de ADN de longitud 1000 y se cuentan los números de GATACA.\n",
    "\n",
    "|veces que aparece|0|1|2|3|4|5|\n",
    "|:-----------------------:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "Freq.empir|229|211|93|35|7|1|\n",
    "\n",
    "En total fueron $n=576$ observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación.** La Poisson puede tomar valores enteros no negativos: $X_0=k$ donde $k=0,1,2,3,...$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Clase|0|1|2|3|4|$\\ge5$|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|Freq.Empir|229|211|93|35|7|1|\n",
    "\n",
    "El estimador de máxima verosimilitud de $\\lambda$ para una Poisson es $\\overline{X}$:\n",
    "\n",
    "clase <- c(0,1,2,3,4,5)\n",
    "\n",
    "freq_empirica <- c(229,211,93,35,7,1)\n",
    "\n",
    "lambda <- sum(Clase * freq_empirica) / sum(freq_empirica)\n",
    "\n",
    "prob_teor <- c(dpois(0,lambda), dpois(1,lambda), dpois(2,lambda), dpois(3,lambda), dpois(4,lambda), 1-ppois(4,lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraste cuando $X_0$ es continua: Test de Kolmogorov-Smirnov\n",
    "\n",
    "El test de bondad y ajuste se puede aplicar cuando $X_0$ es continua o discreta, pero exige que el tamaño de la muestra debe ser grande (debido a las frecuencias esperadas).\n",
    "\n",
    "El test de K-S es un test genérico para contrastar distribuciones continuas. Se puede usar con muestras pequeñas (tamaño al menos 5) **pero la muestra no debe tener valores repetidos**. El $X_0$ de la hipótesis nula debe ser continua y completamente especificada.\n",
    "\n",
    "La idea detrás del proceso es ordenar los datos observados de menor a mayor y construir una función escalonada creciente a partir de esos datos, denotada por $F_n$. El siguiente paso es calcular la *norma infinito* de $F_n-F_{X_0}$, donde $F_{X_0}$ es la distribución de $X_0$. Si llamamos $D_n$ a esta variable aleatoria, se puede demostrar que de ser cierta $\\mathcal{H}_0$, entonces $\\sqrt{n}D_n$ se aproxima a una variable aleatoria conocida como Distribución de Kolmogorov $K$ (Teorema de Kolmogorovo-Smirnov). \n",
    "\n",
    "A pesar de que $n$ tiene que ser grande, se puede hacer un cambio de variable para que el error de aproximar $\\sqrt{n}D_n$ por la distribución de Kolmogorov $K$ sea despreciable (para conocer los detalles de la demostración del test ver [aquí](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La función ks.test\n",
    "\n",
    "Su sintaxis básica es \n",
    "\n",
    "ks.test(x,y,parámetros)\n",
    "\n",
    "donde:\n",
    "\n",
    "x: es la muestra de una variable continua.\n",
    "\n",
    "y: puede ser un segundo vector, y entoces se contrasta si ambos vectores han sido generados por la misma distribución continua; o puede sder el nombre de una función de distribución (empezando por p) que queremos contrastar (y entre comillas). Por ejemplo y = \"pnorm\".\n",
    "\n",
    "parámetros: son los parámetros de distribución si se ha especificado una."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "Verificar si los siguientes datos corresponden a una $N(3,1.5)$: 5.84, 4.57, 1.34, 3.58, 1.54, 2.25\n",
    "\n",
    "muestra <- c(5.84, 4.57, 1.34, 3.58, 1.54, 2.25)\n",
    "\n",
    "ks.test(muestra,\"pnorm\",mean = 3, sd = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "\n",
    "La vida en miles de horas operativas de 10 unidades digitales de una fábrica aeronáutica se ha medido y nos ha dado los siguientes valores: 0.4, 2.6, 4.4, 4.9, 10.6, 11.3, 11.8, 12.6, 23.0, 40.8.\n",
    "\n",
    "Queremos ver si estos datos provienen de una $Exp(\\lambda=0.1)$ (es decir, $\\mathcal{H}_0:Exp(\\lambda=0.1)$) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de normalidad.\n",
    "\n",
    "### Tests de Kolmorogov-Smirnov-Lilliefors (KSM)\n",
    "\n",
    "Para contrastar si una muestra proviene de una $N(\\mu,\\sigma)$, ambos parámetros desconocidos, el test KS nos obliga a tener valores predeterminados. La prueba KSM consiste en estimar dichos parámetros y, detalles más, utilizar la Distribución de Lilliefors en lugar de la de Kolmogorov. Este proceso se usa cuando no conocemos $\\mu$ y $\\sigma$ y *no los queremos calcular*.\n",
    "\n",
    "Uilizamos la librería **nortest**.\n",
    "\n",
    "install.packages(\"nortest\")\n",
    "\n",
    "library(nortest)\n",
    "\n",
    "lillie.test(muestra)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "Verificar si los siguientes datos corresponden a una normal: 5.84, 4.57, 1.34, 3.58, 1.54, 2.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desventaja.**\n",
    "\n",
    "El KSL, aunque es muy sensible a las diferencias entre la muestra y la distribución teórica al rededor de sus valores medios, le cuesta detectar diferencias prominentes en un extremos u otro de la distribución (es decir, que centra mucho de su poder en la información al rededor de la media). Además, aunque se comporte bien con muestras pequeñas (al menos de 5 elementos), llega a fallar con muestras de varios miles de elementos.\n",
    "\n",
    "Por ejemplo, generemos una muestra de una t de Student:\n",
    "\n",
    "``set.seed(100)``\n",
    "\n",
    "``x  <- rt(50,df = 3)``\n",
    "\n",
    "``lillie.test(x)``\n",
    "\n",
    "Sabemos que $x\\sim t_3$. Sin embargo obtenemos ``p-value = 0.2013`` con lo que concluiríamos que $x$ proviene de una normal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Anderson-Darling (AD).\n",
    "\n",
    "Este test resuelve el inconveniente de KSL. Está implementado en la función ``ad.test`` del paquete nortest. \n",
    "\n",
    "Si aplicamos AD a la muestra anterior tenemos ``p-value = 0.004334``, lo que permite rechazar la hipótesis nula de que provenimos de una normal.\n",
    "\n",
    "**Desventaja**\n",
    "\n",
    "Presenta la misma desventaja que el test anterior: aunque se porta bien para muestras pequeñas (de al menos 7 elementos), llega a fallar con muestras de varios miles de elementos. En muestras de este tamaño, cualquier diferencia con una normal se magnifica y en estos dos tests aumenta la probabilidad de errores de tipo I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Shapiro-Wilks (SW).\n",
    "\n",
    "Un test que resuelve este problema es el SW, implementado con la función ``shapiro.test`` de la instalación básica de R (es decir que no requiere de instalar paquetería previa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUY IMPORTANTE\n",
    "\n",
    "Tanto los tests KSL, AD y SW tienen muchos valores repetidos, se pueden ver afectados hasta el punto de que, si hay muchos puntos repetidos, su significado sea falso. El menos afectado es SW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test omnibus de D'Agostino-Pearson.\n",
    "\n",
    "Este test no es sensible a las repeticiones de datos. Está implementado en la función ``dagoTest`` del paquete **fBasics**. Para poder aplicarlo, el tamaño de la muestra debe ser al menos 20. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
